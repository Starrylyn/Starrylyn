# Hanlin Zhao (Zhao Hanlin)

I lead Z.ai [AutoTyper](https://autoglm.zhipuai.cn/autotyper/) (Zhipu AI Input Method) and the [GLM-ASR](https://github.com/zai-org/GLM-ASR) / [GLM-ASR-Nano](https://huggingface.co/zai-org/GLM-ASR-Nano-2512) speech model lines.

What I build is specific: a voice-first writing workflow that lives inside any input field. Users can speak to draft, edit in-place (rewrite, translation, tone/style), and hand off tasks to agent execution (planning + tool-calling) when needed. The most important part is writeback: results return to the same context the user is writing, not to a separate chat window.

I also invest in robustness and evaluation: real-world speech (dialects, quiet speech, noise, mixed languages) and benchmarks that reflect natural prompts. GLM-ASR-Nano-2512 has 502,953 all-time downloads on Hugging Face (as of 2026-02-01).

Earlier at Z.ai: [NaturalCodeBench](https://arxiv.org/abs/2405.04520) (ACL 2024 Findings). I also co-authored work on GUI agents and evaluation: [AutoGLM](https://arxiv.org/abs/2411.00820), [VisualAgentBench](https://arxiv.org/abs/2408.06327), and the [ChatGLM report](https://arxiv.org/abs/2406.12793).

If you're exploring speech input, on-device inference, agent workflows, or benchmark design, feel free to reach out.

:mailbox: hanlin9908@gmail.com Â· :mortar_board: [Google Scholar](https://scholar.google.com/citations?user=2sVac3EAAAAJ&hl=zh-CN)
